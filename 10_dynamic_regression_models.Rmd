# Dynamic regression models

**Learning objectives:**


-  inclusion of other information that may also be relevant

    - the effects of holidays
    - competitor activity
    - changes in the law
    - the wider economy
    - other external variables
    
- extend ARIMA models   


This may explain some of the historical variation and may lead to more accurate forecasts.


## White Noise and Autocorrelation


In this chapter, the authors extend ARIMA models to include other information by allowing `the errors from a regression to contain autocorrelation`. The resulting model has two error terms, with only the ARIMA model errors assumed to be white noise.

<center>
![WHITE NOISE](https://media.giphy.com/media/1lALzcU4pUHWWMGTlK/giphy.gif)
</center>

To incorporate autocorrelation into regression errors, the authors `replace the traditional error term`, $\epsilon_t$, with $\eta_t$, which is `assumed to follow an ARIMA model`. 

$$ y_t=\beta_0 + \beta_1 x_{1,t} + ... + \beta_k x_{k,t} + \eta_t$$

$\eta_t$ follows an ARIMA(1,1,1) model: 

$$(1-\phi_1 B)(1-B)\eta_t(1+\theta_1B)\epsilon_t$$



> A regression model with ARIMA errors is equivalent to a regression model in differences with ARMA errors. 

- all of the variables in the model must first be stationary


## What is the Difference Between ARIMA and ARMA Model?

```{r echo=FALSE, fig.cap = "CC [Credibility Assessment Method of Sensor Data Based on Multi-Source Heterogeneous Information Fusion](https://www.researchgate.net/publication/350642995_Credibility_Assessment_Method_of_Sensor_Data_Based_on_Multi-Source_Heterogeneous_Information_Fusion/figures?lo=1)"}
knitr::include_graphics("images/ch10_arima-vs-arma.png")
```


ARMA model has two components **AR** Auto Regressive and **MA** Moving Average. ARIMA model has an additional component **Integration**.

ARMA models work well on stationary data whereas the ARIMA model works well on non-stationary data.

The integration component in the ARIMA model converts the non-stationary data into stationary data.

Integration is the number of times needed to difference a series in order to achieve stationarity.

ARMA model takes two parameters p and q. $ARMA(p,q)$ where p is the no of lags in the AR model and q is the no of lags in the MA model.
ARIMA model takes three parameters p,d and q. $ARMA(p,d,q)$ where d is no of differencing required to convert non-stationary data into stationary.

$$ARMA(p,q) \sim ARIMA(p,0,q)$$



## Example: US Personal Consumption and Income

Forecast changes in expenditure based on changes in income. In this case data are already stationary, and there is no need for any differencing.

```{r message=FALSE,warning=FALSE}
library(tidyverse)
library(fpp3)
us_change |>
  pivot_longer(c(Consumption, Income),
               names_to = "var", values_to = "value") |>
  ggplot(aes(x = Quarter, y = value)) +
  geom_line() +
  facet_grid(vars(var), scales = "free_y") +
  labs(title = "US consumption and personal income",
       y = "Quarterly % change")
```




```{r}
fit <- us_change |>
  model(ARIMA(Consumption ~ Income))
report(fit)
```

The model relases this ARIMA model selection: $$ARIMA(1,0,2) \text{ ; errors}$$

$$y_t=0.595+0.198x_t+ \eta_t$$
$$\eta_t=0.707 \eta_{t-1}+\varepsilon_t - 0.617 \varepsilon_{t-1}+ 0.207\varepsilon_{t-2}$$
$$\varepsilon_t \sim NID(0,0.311)$$

The `residual()` function applied on the model fit release the estimates for both: 

- $\eta_t$
- $\varepsilon_t$


```{r}
bind_rows(
    `Regression residuals` =
        as_tibble(residuals(fit, type = "regression")),
    `ARIMA residuals` =
        as_tibble(residuals(fit, type = "innovation")),
    .id = "type"
  ) |>
  mutate(
    type = factor(type, levels=c(
      "Regression residuals", "ARIMA residuals"))
  ) |>
  ggplot(aes(x = Quarter, y = .resid)) +
  geom_line() +
  facet_grid(vars(type))
```

```{r}
fit |> gg_tsresiduals()
```
```{r}
augment(fit) |>
  features(.innov, ljung_box, dof = 3, lag = 8)
```
## Forecast
```{r}
us_change_future <- new_data(us_change, 8) |>
  mutate(Income = mean(us_change$Income))
```


```{r}
forecast(fit, new_data = us_change_future) |>
  autoplot(us_change) +
  labs(y = "Percentage change")
```

## Difference between Stochastic and deterministic trends

$$y_t=\beta_0+\beta_1x+\eta_t$$

- Deterministic $\eta_t \sim ARIMA(p,0,q)$ 
- Stochastic $\eta_t \sim ARIMA(p,1,q)$

```{r}
fit_deterministic <- aus_airpassengers |>
  model(deterministic = ARIMA(Passengers ~ 1 + trend() +
                                pdq(d = 0)))

fit_stochastic <- aus_airpassengers |>
  model(stochastic = ARIMA(Passengers ~ pdq(d = 1)))
```


```{r echo=FALSE}
aus_airpassengers |>
  autoplot(Passengers) +
  autolayer(fit_stochastic |> forecast(h = 20),
    colour = "#0072B2", level = 95) +
  autolayer(fit_deterministic |> forecast(h = 20),
    colour = "#D55E00", alpha = 0.65, level = 95) +
  labs(y = "Air passengers (millions)",
       title = "Forecasts from trend models")
```

## Dynamics

For **long seasonal periods**, a `dynamic regression with Fourier terms` is often better than other models:
```{r}
aus_cafe <- aus_retail |>
  filter(
    Industry == "Cafes, restaurants and takeaway food services",
    year(Month) %in% 2004:2018
  ) |>
  summarise(Turnover = sum(Turnover))

fit <- model(aus_cafe,
  `K = 1` = ARIMA(log(Turnover) ~ fourier(K=1) + PDQ(0,0,0)),
  `K = 2` = ARIMA(log(Turnover) ~ fourier(K=2) + PDQ(0,0,0)),
  `K = 3` = ARIMA(log(Turnover) ~ fourier(K=3) + PDQ(0,0,0)),
  `K = 4` = ARIMA(log(Turnover) ~ fourier(K=4) + PDQ(0,0,0)),
  `K = 5` = ARIMA(log(Turnover) ~ fourier(K=5) + PDQ(0,0,0)),
  `K = 6` = ARIMA(log(Turnover) ~ fourier(K=6) + PDQ(0,0,0))
)

fit |>
  forecast(h = "2 years") |>
  autoplot(aus_cafe, level = 95) +
  facet_wrap(vars(.model), ncol = 2) +
  guides(colour = "none", fill = "none", level = "none") +
  geom_label(
    aes(x = yearmonth("2007 Jan"), y = 4250,
        label = paste0("AICc = ", format(AICc))),
    data = glance(fit)
  ) +
  labs(title= "Total monthly eating-out expenditure",
       y="$ billions")
```


## Impact of a predictor

```{r message=FALSE,warning=FALSE}
insurance %>%
  rename(lag0=TVadverts)%>%
  mutate(lag1=lag(lag0),
         lag2=lag(lag0,2))%>%
  pivot_longer(cols = c("lag0","lag1","lag2"),
               names_to = "lags",values_to="TVadverts")%>%
  ggplot(aes(x=TVadverts,y=Quotes,group=lags)) +
  geom_point()+
  geom_smooth()+
  facet_wrap(vars(lags))
```


## Forecast with different levels of TVadverts

Set new data to 20 year-month period time-frame:
```{r eval=FALSE}
new_data(insurance, 20)
```


Sample `TVadverts` ranging from 7 to 10:
```{r}
set.seed(1234)
sample <- sample(7:10,20,replace=T)
```


Create a newdata with sampled TVadverts:
```{r}
insurance_future2 <- new_data(insurance, 20) |>
  mutate(TVadverts = sample)
insurance_future2%>%head
```

Fit the model on sampled TVadverts and plot it:
```{r}
fit_best <- insurance |>
  model(ARIMA(Quotes ~ pdq(d = 0) +
              TVadverts + lag(TVadverts)))
report(fit_best)
```

```{r}
fit_best |>
  forecast(insurance_future2) |>
  autoplot(insurance) +
  labs(
    y = "Quotes",
    title = "Forecast quotes with future advertising\nset to a sample size from 7 to 10"
  )
```

Now create a new data with 4 models each with 7,8,9,10 TVadverts:
```{r}
insurance_future_7 <- new_data(insurance, 20) |>
  mutate(TVadverts = 7)
insurance_future_8 <- new_data(insurance, 20) |>
  mutate(TVadverts = 8)
insurance_future_9 <- new_data(insurance, 20) |>
  mutate(TVadverts = 9)
insurance_future_10 <- new_data(insurance, 20) |>
  mutate(TVadverts = 10)

fit_df_7 <- fit_best |>
  forecast(insurance_future_7)
fit_df_8 <- fit_best |>
  forecast(insurance_future_8)
fit_df_9 <- fit_best |>
  forecast(insurance_future_9)
fit_df_10 <- fit_best |>
  forecast(insurance_future_10)


fit_df_8 <- fit_df_8[2:5]%>%
  rename(TVadverts_8=TVadverts,
         Quotes_8=Quotes,
         .mean_8=.mean)
fit_df_9<- fit_df_9[2:5]%>%
  rename(TVadverts_9=TVadverts,
         Quotes_9=Quotes,
         .mean_9=.mean)
fit_df_10<- fit_df_10[2:5]%>%
  rename(TVadverts_10=TVadverts,
         Quotes_10=Quotes,
         .mean_10=.mean)
```


```{r}
insurance_future <- new_data(insurance, 20) |>
  mutate(TVadverts = 8)
```

```{r}
fit_best_df<-  fit_best |>
  forecast(insurance_future) %>%
  hilo()
```

```{r}
fit_best_df2 <- fit_best_df[2:7]%>%
  mutate(conf_down=as.numeric(sub(".*?(\\d+\\.\\d+).*", "\\1", `80%`)),
         conf_up=as.numeric(sub(".*\\b(\\d+\\.\\d+).*", "\\1", `80%`)),
         conf_down2=as.numeric(sub(".*?(\\d+\\.\\d+).*", "\\1", `95%`)),
         conf_up2=as.numeric(sub(".*\\b(\\d+\\.\\d+).*", "\\1", `95%`)))%>%
  select(-`80%`,-`95%`)
```


```{r}
fit_best_df2_int <- fit_best_df2 %>%
  full_join(insurance%>%select(Month,Quotes),by="Month") 
```

Create new data on those models, 
```{r}
df <- fit_df_7[2:5] %>%
  left_join(fit_df_8, by = "Month") %>%
  left_join(fit_df_9, by = "Month") %>%
  left_join(fit_df_10, by = "Month") %>%
  
  pivot_longer(
    cols = contains("TVadverts"),
    names_to = "TVadverts_num",
    values_to = "TVadverts"
  ) %>%
  pivot_longer(cols = contains(".mean"),
               names_to = "mean_num",
               values_to = ".mean") %>%
  pivot_longer(cols = contains("Quotes"),
               names_to = "Quotes_num",
               values_to = "Quotes") %>%
  distinct() %>%
  arrange(Month)

df %>% head
```
And plot it:
```{r}
ggplot() +
  geom_ribbon(
    data = fit_best_df2_int,
    mapping = aes(x = Month, ymin = conf_down2, ymax = conf_up2),
    fill = "blue",
    alpha = 0.4
  ) +
  geom_ribbon(
    data = fit_best_df2_int,
    mapping = aes(x = Month, ymin = conf_down, ymax = conf_up),
    fill = "blue",
    alpha = 0.2
  ) +
  geom_line(data = insurance, mapping = aes(x = Month, y = Quotes)) +
  geom_line(
    data = df,
    mapping = aes(
      x = Month,
      y = .mean,
      group = mean_num,
      color = mean_num
    )
  ) +
  scale_color_discrete(
    breaks = c(".mean_10",
               ".mean_9",
               ".mean_8",
               ".mean"),
    label = c(
      ".mean" = "7",
      ".mean_8" = "8",
      ".mean_9" = "9",
      ".mean_10" = "10"
    ),
    name = "TVadverts level"
  )
```

## Meeting Videos

### Cohort 2

`r knitr::include_url("https://www.youtube.com/embed/KZbAfdGHc5o")`

`r knitr::include_url("https://www.youtube.com/embed/E22vjAlbrO0")`
